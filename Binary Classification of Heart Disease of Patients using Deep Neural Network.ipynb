{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHpwJChOT9vH"
   },
   "source": [
    "# Binary Classification of Heart Disease of Patients using Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suriya S (225229140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8VBI8UKT9vM"
   },
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xKsYoXMGT9vM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHCoKx8AT9vO"
   },
   "source": [
    "### 1.Load the dataset: “heart_data.csv” and explore the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gF3r2sLGT9vO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "a-2AQnCgT9vP",
    "outputId": "7712f5bc-edb4-4d4a-d28a-9871bd67f305"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAlG1XpRT9vQ",
    "outputId": "680470b4-661f-421f-bae6-87691c004eb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkd6LHwET9vR",
    "outputId": "fca057f8-cd31-45ba-c1e6-a4ebbe2413e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJL4tQ_vT9vS",
    "outputId": "a22172dc-c63b-4bf5-8650-bb7136e6c2e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "GaGgVacST9vT",
    "outputId": "5ac761ff-4fb0-40e4-cc06-7189a3ed3234"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbSHd_uJT9vT",
    "outputId": "d132c909-206c-4b41-b6fb-3818ed1f57b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCehCIeKT9vU",
    "outputId": "be7dd5bb-3314-4b00-e5a2-1c97702d3613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-3QCALUT9vU"
   },
   "source": [
    "### 2. Split the dataset for training and testing (test size = 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i0tl5tP1T9vV"
   },
   "outputs": [],
   "source": [
    "y = df.pop('target')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hyRML6wpT9vV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzLDDN1DT9vV",
    "outputId": "b5569f8a-8d85-458e-a22c-74deb5fe3a19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dgXctm9T9vW",
    "outputId": "a4d6ce5c-4510-4740-86c9-d760ba4518d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR7yjvART9vW"
   },
   "source": [
    "### 3. Create a neural network based on the following requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ8_yuLIT9vW"
   },
   "source": [
    "* Input size = No. of features in X_train = 13\n",
    "* No. of neurons/units in the Dense layer = 8, with Relu activation\n",
    "function\n",
    "* No. of neurons/units in output layer = 1, with sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jBYFEtMFT9vX"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=13, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1aOmnzmT9vX"
   },
   "source": [
    "### 4. Compile your model with learning rate = 0.001, optimizer as ‘RMSprop’, Mean square error loss and metrics as ‘accuracy’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lmKg1EdNT9vX"
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vi6KKbjtT9vY",
    "outputId": "54172a57-cbc7-4657-f1f5-224a4951459e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 4ms/step - loss: 0.4548 - accuracy: 0.5413\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.5496\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ba09d45b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer = optimizer, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs =10, batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiczwvIlT9vY",
    "outputId": "828760ba-f988-4ba4-ea74-7cc8c54bd8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step - loss: 0.4754 - accuracy: 0.5246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4754098355770111, 0.5245901346206665]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdtHbkp6T9vY"
   },
   "source": [
    "### 5. Print the summary of the model: model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lkw5gc2qWcMc",
    "outputId": "4559d7cd-e50e-4133-8a81-6a3f2b725e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIcoM2f9WTJO"
   },
   "source": [
    "### 6. Train the model for 200 epochs and batch size as 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZggXOgQWvZa",
    "outputId": "9f8b6a9d-9289-4f05-c636-39a021dd6428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.5455\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.5496\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.5413\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.5496\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.5496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ba1d97580>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer = optimizer, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs =200, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5N-OBdzPW5xz",
    "outputId": "ca7865bc-63e4-4161-e556-d9072351c30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.5246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4754098355770111, 0.5245901346206665]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6z9pMCYXvDa"
   },
   "source": [
    "### 7. Save the trained model in a variable, such as, history. Also, you can split your training data for validation such as 20% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvL19sBJYD_O",
    "outputId": "5a5f082d-0cf4-4c68-ff62-c01b4bda7ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train,y_train,validation_split =0.2,epochs=100, batch_size =10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgQmSv8TZqAj"
   },
   "source": [
    "### 8. Evaluate the trained model to predict the probability values for the test data set (ie., xtest and ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gulBtslTYEzt",
    "outputId": "4b6070fd-d28d-4523-9177-1bf5be35a468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4754 - accuracy: 0.5246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4754098355770111, 0.5245901346206665]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RZsLW-UZm89"
   },
   "source": [
    "### 9. Print the model accuracy and model loss as below (Use can use the ‘history’ object we have saved). Sample code is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DApiCSWZtfq",
    "outputId": "bc7c634a-954c-4c36-c215-75f9b6a1943a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "OSeXcMoRZuG0",
    "outputId": "cb9a60ab-6329-4606-edd6-efc58d207021"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8sRsHwdZuP2"
   },
   "source": [
    "### 10. Do further experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bzh3zZZZZugz"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(16, input_dim=13, activation='relu'))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sgL6lAJatEG",
    "outputId": "de47d965-277c-462f-c093-183b78b22ac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 4ms/step - loss: 0.4204 - accuracy: 0.5620\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2509 - accuracy: 0.6405\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.6198\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.6198\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.6198\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2728 - accuracy: 0.6322\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2662 - accuracy: 0.6281\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.7066\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.6405\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2487 - accuracy: 0.6240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ba47f0190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "model1.fit(X_train, y_train, epochs=10, batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-NUFClTauLD",
    "outputId": "17e80d37-4c63-4345-9ac2-0147c75cd9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.5246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3771623969078064, 0.5245901346206665]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZRTisuOaw8F",
    "outputId": "bef383fc-1dd6-48cc-adf4-5899206cdba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.5440 - val_loss: 0.4286 - val_accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_wm7w0ua0a1",
    "outputId": "9d2dbd54-64be-4330-cbd1-2220bc8d18dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 16)                224       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rAG5BPNta5NO"
   },
   "outputs": [],
   "source": [
    "ls = history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "KmSRfxsHa7Um",
    "outputId": "4a890ba4-8f8b-4863-f2ab-44ef08bf3494"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.455959  0.544041  0.428571      0.571429\n",
       "1   0.455959  0.544041  0.428571      0.571429\n",
       "2   0.455959  0.544041  0.428571      0.571429\n",
       "3   0.455959  0.544041  0.428571      0.571429\n",
       "4   0.455959  0.544041  0.428571      0.571429\n",
       "..       ...       ...       ...           ...\n",
       "95  0.455959  0.544041  0.428571      0.571429\n",
       "96  0.455959  0.544041  0.428571      0.571429\n",
       "97  0.455959  0.544041  0.428571      0.571429\n",
       "98  0.455959  0.544041  0.428571      0.571429\n",
       "99  0.455959  0.544041  0.428571      0.571429\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.DataFrame.from_dict(ls)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_6ISUz0ya9Z2"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=13, activation='relu'))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyCs4gombANn",
    "outputId": "87ee20c8-3c4b-49de-a884-536f5cc26237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.5496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ba499ab20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVPbSV_ubCaA",
    "outputId": "0ea2c4d6-fa46-4272-e292-0b76f4050ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.5246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4754098355770111, 0.5245901346206665]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZgjO9xxbPix",
    "outputId": "0515bcd4-32f8-42fd-b661-d98cc4ac045d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 32)                448       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WdKUa505bRrQ"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(64, input_dim=13, activation='relu'))\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(16, activation='relu'))\n",
    "model3.add(Dense(8, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SMfNcmQbUXZ",
    "outputId": "d5006f3c-9f02-438c-aee4-c259bea5732d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 5ms/step - loss: 0.4341 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.5579\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2616 - accuracy: 0.6198\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.6529\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2326 - accuracy: 0.6529\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.6529\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.6694\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2037 - accuracy: 0.6818\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2590 - accuracy: 0.6322\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2301 - accuracy: 0.6488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ba5aac580>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "model3.fit(X_train, y_train, epochs=10, batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agZt4CmfbWaX",
    "outputId": "7d0742d4-bb13-4ca1-aad7-ff818d237fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1846 - accuracy: 0.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18456268310546875, 0.7377049326896667]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDTap24hbY-Z",
    "outputId": "82a384a0-7c58-4e4f-9250-75e13ec26481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                896       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,649\n",
      "Trainable params: 3,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PDL Lab-3 215229135.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
