{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39309648",
   "metadata": {},
   "source": [
    "# Text corpus creation and binary classification using DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cab351",
   "metadata": {},
   "source": [
    "## Suriya S (225229140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c96dc",
   "metadata": {},
   "source": [
    "###  1. Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6830d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\online.CSCENTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\online.CSCENTER\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7aadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Quotes.csv\",encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699670eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3f9ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The purpose of our lives is to be happy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Life is what happens when you're busy making o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get busy living or get busy dying.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You only live once, but if you do it right, on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you want to live a happy life, tie it to a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Target\n",
       "0           The purpose of our lives is to be happy.       0\n",
       "1  Life is what happens when you're busy making o...       0\n",
       "2                 Get busy living or get busy dying.       0\n",
       "3  You only live once, but if you do it right, on...       0\n",
       "4  If you want to live a happy life, tie it to a ...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6413aeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence\n",
       "Target          \n",
       "0             20\n",
       "1             20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71132bc0",
   "metadata": {},
   "source": [
    "### 2. Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62d7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.Sentence\n",
    "y=df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bc3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0560f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "\n",
    "    tokens = review.lower().split()\n",
    "    filtered_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5bb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\online.CSCENTER\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8de8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=X.tolist()\n",
    "fax=[]\n",
    "for i in temp:\n",
    "    fax.append(clean_review(i))\n",
    "n_X=pd.Series(fax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a934e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolutely</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>always</th>\n",
       "      <th>anyone</th>\n",
       "      <th>anything</th>\n",
       "      <th>apart</th>\n",
       "      <th>are</th>\n",
       "      <th>baby</th>\n",
       "      <th>best</th>\n",
       "      <th>...</th>\n",
       "      <th>watching</th>\n",
       "      <th>way</th>\n",
       "      <th>whole</th>\n",
       "      <th>work</th>\n",
       "      <th>worked</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360988</td>\n",
       "      <td>0.360988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368583</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.415398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    absolutely     again       all    always    anyone  anything     apart  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15    0.000000  0.000000  0.000000  0.380638  0.000000  0.000000  0.000000   \n",
       "16    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "19    0.000000  0.000000  0.000000  0.000000  0.360988  0.360988  0.000000   \n",
       "20    0.000000  0.301961  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "21    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "22    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "23    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "24    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "25    0.415398  0.000000  0.000000  0.343781  0.000000  0.000000  0.000000   \n",
       "26    0.000000  0.000000  0.000000  0.000000  0.367350  0.000000  0.000000   \n",
       "27    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "28    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "29    0.000000  0.000000  0.000000  0.442786  0.000000  0.000000  0.000000   \n",
       "30    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.473323   \n",
       "31    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "32    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "33    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "34    0.000000  0.000000  0.355563  0.000000  0.000000  0.639408  0.000000   \n",
       "35    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "36    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "37    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "38    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "39    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         are      baby      best  ...  watching  way     whole      work  \\\n",
       "0   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.340863  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  ...  0.000000  0.5  0.000000  0.000000   \n",
       "11  0.471752  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.773539  ...  0.000000  0.0  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.520939   \n",
       "15  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "19  0.000000  0.401477  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "23  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "24  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "30  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "31  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "32  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "33  0.000000  0.000000  0.000000  ...  0.468684  0.0  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "38  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.000000  ...  0.000000  0.0  0.496972  0.000000   \n",
       "\n",
       "      worked  world     write     wrong  yesterday       you  \n",
       "0   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "1   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "2   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "3   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "4   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "5   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "6   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "7   0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "8   0.000000    0.0  0.454792  0.000000   0.000000  0.000000  \n",
       "9   0.000000    0.0  0.000000  0.000000   0.000000  0.347101  \n",
       "10  0.000000    0.5  0.000000  0.000000   0.000000  0.000000  \n",
       "11  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "12  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "13  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "14  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "15  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "16  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "17  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "18  0.507772    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "19  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "20  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "21  0.000000    0.0  0.000000  0.000000   0.368583  0.000000  \n",
       "22  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "23  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "24  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "25  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "26  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "27  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "28  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "29  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "30  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "31  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "32  0.000000    0.0  0.000000  0.000000   0.000000  0.333722  \n",
       "33  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "34  0.000000    0.0  0.000000  0.355563   0.000000  0.000000  \n",
       "35  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "36  0.000000    0.0  0.000000  0.000000   0.000000  0.382721  \n",
       "37  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "38  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "39  0.000000    0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "\n",
       "[40 rows x 158 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "vectors = tfidf.fit_transform(n_X)\n",
    "features_name = tfidf.get_feature_names()\n",
    "text_vect = pd.DataFrame(vectors.todense(),columns=features_name)\n",
    "text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c939bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp = tf.Variable(text_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14d382",
   "metadata": {},
   "source": [
    "### 3. Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8c60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(text_vect,y,train_size=0.75,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f4830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 158)\n",
      "(30,)\n",
      "(10, 158)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72371e83",
   "metadata": {},
   "source": [
    "### 4. Model Creation:\n",
    "\n",
    "### 5. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0026e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0193bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               20352     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,370\n",
      "Trainable params: 31,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu',input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid')) #output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe6126f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 0s - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6913 - val_accuracy: 0.5000 - 421ms/epoch - 211ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6819 - accuracy: 0.5000 - val_loss: 0.6909 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.6745 - accuracy: 0.5000 - val_loss: 0.6896 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.6651 - accuracy: 0.5000 - val_loss: 0.6875 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.6564 - accuracy: 0.5000 - val_loss: 0.6852 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.6472 - accuracy: 0.5000 - val_loss: 0.6827 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.6362 - accuracy: 0.5000 - val_loss: 0.6803 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.6240 - accuracy: 0.5417 - val_loss: 0.6776 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.6103 - accuracy: 0.5417 - val_loss: 0.6756 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.5965 - accuracy: 0.5417 - val_loss: 0.6739 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.5792 - accuracy: 0.5833 - val_loss: 0.6729 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.5616 - accuracy: 0.6250 - val_loss: 0.6739 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.5418 - accuracy: 0.6667 - val_loss: 0.6769 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 0.5219 - accuracy: 0.7083 - val_loss: 0.6820 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 0.5002 - accuracy: 0.7083 - val_loss: 0.6908 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 0.4777 - accuracy: 0.7917 - val_loss: 0.7019 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 0.4545 - accuracy: 0.7917 - val_loss: 0.7175 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 0.4342 - accuracy: 0.9167 - val_loss: 0.7454 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 0.4153 - accuracy: 0.8750 - val_loss: 0.7788 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 0.3953 - accuracy: 0.9583 - val_loss: 0.8118 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 0.3799 - accuracy: 1.0000 - val_loss: 0.8587 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 0.3693 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 0.3584 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 0.3501 - accuracy: 1.0000 - val_loss: 1.0070 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 0.3445 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 0.3398 - accuracy: 1.0000 - val_loss: 1.1360 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 0.3362 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 0.3332 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 0.3308 - accuracy: 1.0000 - val_loss: 1.2857 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 0.3288 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 0.3271 - accuracy: 1.0000 - val_loss: 1.3768 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 0.3254 - accuracy: 1.0000 - val_loss: 1.4198 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 0.3238 - accuracy: 1.0000 - val_loss: 1.4601 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 0.3224 - accuracy: 1.0000 - val_loss: 1.4913 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 0.3211 - accuracy: 1.0000 - val_loss: 1.5152 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 0.3197 - accuracy: 1.0000 - val_loss: 1.5377 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 0.3184 - accuracy: 1.0000 - val_loss: 1.5573 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 0.3171 - accuracy: 1.0000 - val_loss: 1.5744 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 0.3159 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 0.3147 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 0.3135 - accuracy: 1.0000 - val_loss: 1.6102 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 0.3123 - accuracy: 1.0000 - val_loss: 1.6056 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 0.3110 - accuracy: 1.0000 - val_loss: 1.6036 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 0.3100 - accuracy: 1.0000 - val_loss: 1.6027 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 0.3088 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 0.3075 - accuracy: 1.0000 - val_loss: 1.6045 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 0.3064 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 0.3053 - accuracy: 1.0000 - val_loss: 1.6073 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 0.3040 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 0.3027 - accuracy: 1.0000 - val_loss: 1.6108 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 0.3016 - accuracy: 1.0000 - val_loss: 1.6120 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 0.3004 - accuracy: 1.0000 - val_loss: 1.6128 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 0.2990 - accuracy: 1.0000 - val_loss: 1.6108 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 0.2977 - accuracy: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 0.2965 - accuracy: 1.0000 - val_loss: 1.6018 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 0.2951 - accuracy: 1.0000 - val_loss: 1.5955 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 0.2938 - accuracy: 1.0000 - val_loss: 1.5896 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 0.2924 - accuracy: 1.0000 - val_loss: 1.5842 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 0.2909 - accuracy: 1.0000 - val_loss: 1.5798 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 0.2898 - accuracy: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 0.2881 - accuracy: 1.0000 - val_loss: 1.5485 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 0.2865 - accuracy: 1.0000 - val_loss: 1.5343 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 0.2850 - accuracy: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 0.2836 - accuracy: 1.0000 - val_loss: 1.5070 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 0.2818 - accuracy: 1.0000 - val_loss: 1.4994 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 0.2801 - accuracy: 1.0000 - val_loss: 1.4922 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 0.2784 - accuracy: 1.0000 - val_loss: 1.4853 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 0.2767 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 0.2748 - accuracy: 1.0000 - val_loss: 1.4522 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 0.2728 - accuracy: 1.0000 - val_loss: 1.4326 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 0.2709 - accuracy: 1.0000 - val_loss: 1.4151 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 0.2684 - accuracy: 1.0000 - val_loss: 1.3995 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 0.2662 - accuracy: 1.0000 - val_loss: 1.3730 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 0.2636 - accuracy: 1.0000 - val_loss: 1.3335 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 0.2612 - accuracy: 1.0000 - val_loss: 1.2880 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 0.2583 - accuracy: 1.0000 - val_loss: 1.2390 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 0.2554 - accuracy: 1.0000 - val_loss: 1.1859 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 0.2522 - accuracy: 1.0000 - val_loss: 1.1302 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 0.2483 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 0.2443 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 0.2398 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 0.2348 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 0.1992 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 0.1889 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 0.1639 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8333 - 14ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.8333 - 13ms/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 0.1341 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8333 - 14ms/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 0.1156 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.8333 - 13ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8333 - 13ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8333 - 12ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.8333 - 14ms/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.8333 - 14ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.8333 - 13ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.8333 - 13ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 1.0000 - 13ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d32fc84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0093 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.00928795337677, 0.5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36534bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bb680",
   "metadata": {},
   "source": [
    "#### Model with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a6d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(512, activation='relu',input_dim=X_train.shape[1]))\n",
    "model2.add(Dense(256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53de288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               81408     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,018\n",
      "Trainable params: 254,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(2, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd7d668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 0s - loss: 0.6942 - accuracy: 0.4583 - val_loss: 0.6943 - val_accuracy: 0.3333 - 332ms/epoch - 166ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6415 - accuracy: 0.9583 - val_loss: 0.6926 - val_accuracy: 0.3333 - 17ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.5912 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.5306 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.4599 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.3768 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.2780 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.1783 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.6667 - 15ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 7.4976e-04 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 0.6667 - 16ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 2.5658e-04 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 1.0622e-04 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 5.0900e-05 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 2.4557e-05 - accuracy: 1.0000 - val_loss: 0.7909 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 1.3922e-05 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 8.6625e-06 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 5.6723e-06 - accuracy: 1.0000 - val_loss: 0.7910 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 3.9935e-06 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 2.8958e-06 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 2.2600e-06 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 1.8626e-06 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 1.5547e-06 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 1.3312e-06 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 1.2070e-06 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 1.0878e-06 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 9.9341e-07 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 9.2387e-07 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 8.7917e-07 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 8.3446e-07 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 8.0466e-07 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 7.8976e-07 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 7.5996e-07 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 7.4506e-07 - accuracy: 1.0000 - val_loss: 0.7948 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 7.3016e-07 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 7.1525e-07 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 7.1029e-07 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 6.9539e-07 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 6.9539e-07 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 6.8545e-07 - accuracy: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 6.8545e-07 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 6.8049e-07 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 6.7055e-07 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 6.7055e-07 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 6.6558e-07 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 6.6062e-07 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 6.5068e-07 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 6.5068e-07 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 6.5068e-07 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 6.4572e-07 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 6.3578e-07 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 6.3578e-07 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 6.3578e-07 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 6.3578e-07 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 6.3578e-07 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 6.3082e-07 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 6.3082e-07 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 6.3082e-07 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 6.3082e-07 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 6.3082e-07 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 6.3082e-07 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 6.2585e-07 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 6.2585e-07 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 6.2585e-07 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 6.2585e-07 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 6.2088e-07 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 6.2088e-07 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 6.1591e-07 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 6.0598e-07 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 6.0598e-07 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 6.0598e-07 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 6.0598e-07 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 6.0598e-07 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 6.0101e-07 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 5.9605e-07 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 5.9108e-07 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 5.8114e-07 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 5.8114e-07 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 5.7618e-07 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model2.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "772211e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0528 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0527589321136475, 0.6000000238418579]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b147d4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a79e06",
   "metadata": {},
   "source": [
    "#### Model with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "882f7f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 1028)              163452    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               526848    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 822,142\n",
      "Trainable params: 822,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(1028, activation='relu',input_dim=X_train.shape[1]))\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dense(2, activation='sigmoid')) #output layer\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4958265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 0s - loss: 0.7040 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000 - 319ms/epoch - 160ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6133 - accuracy: 0.9167 - val_loss: 0.6811 - val_accuracy: 0.6667 - 17ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.5307 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8333 - 18ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.4201 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.8333 - 19ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.2817 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 1.0000 - 18ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 1.0000 - 18ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 1.0000 - 19ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.6667 - 19ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 8.0942e-04 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 1.9853e-04 - accuracy: 1.0000 - val_loss: 0.5238 - val_accuracy: 0.5000 - 19ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 4.6425e-05 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.5000 - 21ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 1.2442e-05 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 4.4256e-06 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 1.5994e-06 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 6.9539e-07 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 3.3776e-07 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 1.6391e-07 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 7.4506e-08 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 4.9671e-08 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 3.4769e-08 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 0.9043 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 9.9341e-09 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 9.9341e-09 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 9.9341e-09 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 9.9341e-09 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 4.9671e-09 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.5000 - 19ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 4.9671e-09 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 4.9671e-09 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 4.9671e-09 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 4.9671e-09 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.5000 - 19ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9801 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9873 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.5000 - 21ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.5000 - 19ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9924 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.5000 - 21ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9929 - val_accuracy: 0.5000 - 19ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.5000 - 19ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 20ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 19ms/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 16ms/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 18ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.5000 - 17ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model3.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64117764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1530 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1530239582061768, 0.4000000059604645]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "965b2d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbcc825",
   "metadata": {},
   "source": [
    "#### Model with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5c33a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                10176     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,322\n",
      "Trainable params: 12,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(64, activation='relu',input_dim=X_train.shape[1]))\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(Dense(2, activation='sigmoid')) #output layer\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e9cb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 0s - loss: 0.7007 - accuracy: 0.4583 - val_loss: 0.7135 - val_accuracy: 0.5000 - 284ms/epoch - 142ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6878 - accuracy: 0.5417 - val_loss: 0.7120 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.6773 - accuracy: 0.6250 - val_loss: 0.7111 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.6666 - accuracy: 0.7500 - val_loss: 0.7110 - val_accuracy: 0.3333 - 15ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.6569 - accuracy: 0.8333 - val_loss: 0.7112 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.6471 - accuracy: 0.8333 - val_loss: 0.7111 - val_accuracy: 0.3333 - 13ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.6373 - accuracy: 0.8333 - val_loss: 0.7112 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.6274 - accuracy: 0.8750 - val_loss: 0.7115 - val_accuracy: 0.3333 - 13ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.6172 - accuracy: 0.9167 - val_loss: 0.7119 - val_accuracy: 0.3333 - 13ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.6057 - accuracy: 0.9167 - val_loss: 0.7125 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.5943 - accuracy: 0.9583 - val_loss: 0.7130 - val_accuracy: 0.3333 - 13ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.5815 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.5681 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.3333 - 13ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 0.5545 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.3333 - 13ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 0.5396 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.3333 - 13ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 0.5239 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 0.5075 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.3333 - 14ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 0.4908 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 0.4726 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 0.4543 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 0.4349 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.5000 - 13ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 0.4150 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 0.3952 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 0.3741 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 0.3535 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.5000 - 15ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 0.3326 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.5000 - 15ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 0.2911 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 0.2705 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 0.2505 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 0.1945 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 0.1776 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 0.1617 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.6667 - 15ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 0.1469 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 0.1202 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.6336 - val_accuracy: 0.6667 - 15ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.6667 - 15ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.6667 - 15ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.6667 - 15ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5962 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5888 - val_accuracy: 0.5000 - 13ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.5000 - 14ms/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.5000 - 12ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5846 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5775 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.6667 - 13ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.6667 - 12ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.6667 - 14ms/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5744 - val_accuracy: 0.6667 - 13ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model4.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7150a552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
